# -*- coding: utf-8 -*-
"""NSAC_train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wNMXZctHiiF2zj7eYbMbOqRICs1BTo10
"""



!wget "https://www.dropbox.com/s/rl0qbub4clah2w9/grid_version.tar"

!tar -xvf 'grid_version.tar'

train_input_folder ='grid_version/train'
validate_input_folder = 'grid_version/validation'

from imutils import paths
import os
import shutil
import random

def split_data(directory, validate_directory='validation', split=0.8): 
  directories = [os.path.join(directory, o) for o in os.listdir(directory) 
                    if os.path.isdir(os.path.join(directory,o))]
  print(directories)
  for directory in directories:
    image_paths = list(paths.list_images(directory))
    
    random.seed(32)
    random.shuffle(image_paths)
    image_paths
   
    # compute the training and testing split
    i = int(len(image_paths) * split)    
    train_paths = image_paths[:i]
    selected_for_validation_paths = image_paths[i:]
    for path in selected_for_validation_paths:
       category = os.path.basename(os.path.normpath(directory))
       dest_path = os.path.join(validate_directory, category)
       if not os.path.exists(dest_path):
           os.makedirs(dest_path)
       shutil.move(path, dest_path)

!ls grid_version/validation

split_data(directory='grid_version/train/', validate_directory='grid_version/validation')

!ls grid_version/validation/grid_smoke

!ls grid_version/validation/grid_no_smoke

from tensorflow.keras.preprocessing.image import ImageDataGenerator

#apply image augmentation
train_image_generator =  ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True)
"""ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    brightness_range=[0.5, 1.5],
    rotation_range=40)"""
    
validate_image_generator = ImageDataGenerator(rescale=1./255)

batch_size = 16 #40
image_width = 150 #224
image_height = 150 #223
IMAGE_WIDTH_HEIGHT = (image_width, image_height)

class_mode = 'binary'


train_generator = train_image_generator.flow_from_directory(
            train_input_folder,
            target_size=IMAGE_WIDTH_HEIGHT,
            batch_size=batch_size,
            class_mode=class_mode)
            

validation_generator = validate_image_generator.flow_from_directory(
        validate_input_folder,
        target_size=IMAGE_WIDTH_HEIGHT,
        batch_size=batch_size,
        class_mode=class_mode)

import matplotlib.pyplot as plt
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

sample_training_images, _ = next(train_generator)
plotImages(sample_training_images[:100])

from tensorflow.keras import layers
from tensorflow.keras import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense
from tensorflow.keras import backend as K
 
img_input = layers.Input(shape=(image_width, image_height, 3))
input_shape = (image_width, image_height, 3)
 
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=input_shape))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
 
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
 
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
 
model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))
 
model.compile(loss='binary_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])
 
"""
total_classes = 1
activation_function = 'sigmoid'
loss = 'binary_crossentropy'
img_input = layers.Input(shape=(image_width, image_height, 3))
 
x = layers.Conv2D(32, 3, activation='relu')(img_input)
x = layers.MaxPooling2D(2)(x)
 
x = layers.Conv2D(64, 3, activation='relu')(x)
x = layers.MaxPooling2D(2)(x)
 
x = layers.Flatten()(x)
 
x = layers.Dense(512, activation='relu')(x)
 
x = layers.Dropout(0.5)(x)
 
output = layers.Dense(total_classes, activation= activation_function)(x)
 
model = Model(img_input, output)
 
model.compile(loss=loss,
              optimizer=Adam(lr=0.001),
              metrics=['accuracy'])"""

import datetime, os
import tensorflow as tf

epochs = 10
steps_per_epoch = train_generator.n // train_generator.batch_size
validation_steps = validation_generator.n // validation_generator.batch_size

logdir = os.path.join("tf_logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

history = model.fit_generator(
      train_generator,
      steps_per_epoch=steps_per_epoch,
      validation_data=validation_generator,
      validation_steps=validation_steps,
      epochs=epochs,
      callbacks=[tensorboard_callback])

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
 
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
 
loss = history.history['loss']
val_loss = history.history['val_loss']
 
plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.ylabel('Accuracy')
plt.ylim([min(plt.ylim()), 1])
plt.title('Training and Validation Accuracy')
 
plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.ylabel('Cross Entropy')
plt.ylim([0, 1.0])
plt.title('Training and Validation Loss')
plt.xlabel('epoch')